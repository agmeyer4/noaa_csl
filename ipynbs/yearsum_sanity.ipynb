{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity Check: Yearly SLC totals against other inventories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import os\n",
    "import pyproj\n",
    "import numpy as np\n",
    "import xesmf as xe\n",
    "import calendar\n",
    "import datetime\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import noaa_csl_funcs as ncf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define classes\n",
    "class Regridded_CSL_Handler:\n",
    "    '''A class to handle NOAA CSL inventory data that has been regridded and organized by regrid_data.py'''\n",
    "\n",
    "    def __init__(self,regridded_path,bau_or_covid='COVID'):\n",
    "        '''Everything revolves around the \"regridded_path\", which determines sectors via the filenames contained within'''\n",
    "\n",
    "        self.regridded_path = regridded_path\n",
    "        self.sectors = self.get_sectors()\n",
    "        self.bau_or_covid = bau_or_covid\n",
    "\n",
    "    def get_sectors(self):\n",
    "        '''Lists the sectors in the regridded data storage path'''\n",
    "\n",
    "        sector_list = ncf.listdir_visible(self.regridded_path)\n",
    "        sectors = {'area':[],'point':[]}\n",
    "        for sector in sector_list:\n",
    "            if 'area' in sector:\n",
    "                sectors['area'].append(sector)\n",
    "            elif 'point' in sector:\n",
    "                sectors['point'].append(sector)\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected sector type {sector}, not point or area.\")\n",
    "        return sectors\n",
    "\n",
    "    def get_sector_subset_list(self,sector_subset):\n",
    "        '''Gets a subset of the sectors which could be one, all, or some\n",
    "        \n",
    "        Args:\n",
    "        sector_subset (str,list): \"all\" will return all sectors,  'point' will return point sectors, 'area' will return area sectors, a list will just return that list\n",
    "        \n",
    "        Returns:\n",
    "        sector_subset_list (list) : list of sectors in the subset. \n",
    "        '''\n",
    "\n",
    "        if sector_subset == 'all':\n",
    "            sector_subset_list = []\n",
    "            for k,v in self.sectors.items():\n",
    "                sector_subset_list.extend(v)\n",
    "            return sector_subset_list\n",
    "        elif type(sector_subset)==str:\n",
    "            return self.sectors[sector_subset]\n",
    "        else:\n",
    "            return sector_subset\n",
    "\n",
    "    def get_days_in_range(self,dt1,dt2,day_types,sector_subset = 'all',add_path=True):\n",
    "        '''Gets all filepaths to the day_type level that are within a datetime range\n",
    "        \n",
    "        Args:\n",
    "        dt1 (datetime.date) : a date, datetime, etc to start the range (will only use year and month)\n",
    "        dt2 (datetime.date) : a date, datetime, etc to end the range (will only use year and month)\n",
    "        sectors (list) : list of sectors to include in the list\n",
    "        day_types (list) : list of day types to include in the list\n",
    "        add_path (bool, optional) : if true (default) it will add the regridded path to each element\n",
    "\n",
    "        Returns:\n",
    "        days_in_range (list) : list of paths to files that are within the date range and sector, day_types, etc. \n",
    "        '''\n",
    "\n",
    "        dates_list = pd.date_range(dt1,dt2,freq = 'MS') #get a list of all the months between the dts\n",
    "        sector_subset_list = self.get_sector_subset_list(sector_subset)\n",
    "        days_in_range = []\n",
    "        for date in dates_list:\n",
    "            for sector in sector_subset_list:\n",
    "                for day_type in day_types:\n",
    "                    day_path = f'{sector}/{ncf.yr_to_yrstr(sector,date.year,self.bau_or_covid)}/{ncf.month_int_to_str(date.month)}/{day_type}'\n",
    "                    if add_path:\n",
    "                        days_in_range.append(os.path.join(self.regridded_path,day_path))\n",
    "                    else:\n",
    "                        days_in_range.append(day_path)\n",
    "        return days_in_range\n",
    "    \n",
    "    def get_files_in_days(self,days_paths):\n",
    "        '''Gets the files that exist in the paths\n",
    "        \n",
    "        Args:\n",
    "        days_path (list) : list of paths to the days folders\n",
    "        \n",
    "        Returns:\n",
    "        files (list) : list of files in those days' paths'''\n",
    "\n",
    "        files = []\n",
    "        for day_path in days_paths:\n",
    "            files.extend(ncf.listdir_visible(day_path,add_path=True))\n",
    "        return files\n",
    "\n",
    "\n",
    "#Defime Functions\n",
    "def preprocess_regridded(ds,extent,area_point):\n",
    "    '''Preprocesses the regridded dataset when loaded to add attributes needed for concatenation\n",
    "    \n",
    "    Args:\n",
    "    ds (xr.DataSet) : the dataset to process\n",
    "    \n",
    "    Returns \n",
    "    ds (xr.DataSet) : the dataset, with added coordinates taken from the attributes\n",
    "    '''\n",
    "    if area_point == 'area':\n",
    "        ds = ds.assign_coords(sector = 'area_'+ ds.attrs['sector_id']) #add back the area, was cut off in attributes for some reason\n",
    "    else:\n",
    "        ds = ds.assign_coords(sector = 'point_'+ ds.attrs['sector_id']) #add back the area, was cut off in attributes for some reason\n",
    "    ds = ds.assign_coords(day_type = ds.attrs['day_type']) \n",
    "    ds = ds.assign_coords(yr_mo=f'{ds.attrs['year']}-{ds.attrs['month']}')\n",
    "    ds = ds.expand_dims(dim=['sector','day_type','yr_mo'])\n",
    "    if area_point == 'area':\n",
    "        ds = slice_extent(ds,extent)\n",
    "    else:\n",
    "        ds = ds.where(((ds.lat>=extent['lat_low'])&\n",
    "                        (ds.lat<=extent['lat_high'])&\n",
    "                        (ds.lon>=extent['lon_low'])&\n",
    "                        (ds.lon<=extent['lon_high'])).compute(),drop=True)\n",
    "    try:\n",
    "        del ds.attrs['nc_fpath']\n",
    "    except:\n",
    "        pass\n",
    "    return ds\n",
    "\n",
    "def slice_extent(ds,extent):\n",
    "    ds = ds.sel(lat=slice(extent['lat_low'],extent['lat_high']),lon=slice(extent['lon_low'],extent['lon_high']))\n",
    "    return ds \n",
    "\n",
    "def get_satsunwkd(year,month):\n",
    "    '''Gets the number of saturdays, sundays and weekdays in a given month+year\n",
    "    \n",
    "    Args:\n",
    "    year (int) : the year\n",
    "    month (int) : the month, as an integer\n",
    "    \n",
    "    Returns:\n",
    "    sat_count (int) : number of saturdays\n",
    "    sun_count (int) : number of sundays\n",
    "    weekd_count (int) : number of weekdays\n",
    "    '''\n",
    "\n",
    "    num_days_in_month = calendar.monthrange(year,month)[1]\n",
    "    month_str = f'{month:02d}'\n",
    "\n",
    "    dow_ints = list(pd.date_range(start=f'{year}-{month_str}-01',end=f'{year}-{month_str}-{num_days_in_month}').weekday)\n",
    "    sat_count = len([ dow for dow in dow_ints if dow == 5 ])\n",
    "    sun_count = len([ dow for dow in dow_ints if dow == 6 ])\n",
    "    weekd_count = len([ dow for dow in dow_ints if dow < 5 ])\n",
    "    return sat_count,sun_count,weekd_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_extent={'lon_low':-112.25,\n",
    "            'lon_high':-111.55,\n",
    "            'lat_low':40.3,\n",
    "            'lat_high':41.1} \n",
    "dataset_extent = {'lon_low':-112.1,\n",
    "                  'lon_high':-111.7,\n",
    "                  'lat_low':40.4,\n",
    "                  'lat_high':41.0} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "regridded_path = '/uufs/chpc.utah.edu/common/home/lin-group9/agm/NOAA_CSL_Data/regridded'\n",
    "RCH = Regridded_CSL_Handler(regridded_path)\n",
    "dt1  = '2019-01' #start year and month\n",
    "dt2 = '2019-12' #end year and month\n",
    "day_types = ['weekdy','satdy','sundy'] #a list with any or all of 'weekdy','satdy','sundy'\n",
    "species = 'CO'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get area sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors = 'area'\n",
    "\n",
    "#Get the paths to the files that match the criteria\n",
    "days_paths = RCH.get_days_in_range(dt1,dt2,day_types,sectors) \n",
    "files = RCH.get_files_in_days(days_paths)\n",
    "\n",
    "#Load the files with xarray, preprocessing them so they can be combined by coordinates\n",
    "ds_list = [] #initialize the list of datasets\n",
    "for file in files:\n",
    "    ds = preprocess_regridded(xr.open_dataset(file,chunks = {'utc_hour':1}),dataset_extent,sectors)[species] #prepreprocess the file, open with dask chunking, and only keep the species of interest\n",
    "    ds_list.append(ds)  \n",
    "ds_combined = xr.combine_by_coords(ds_list,combine_attrs='drop_conflicts') #this is the combined dataset!\n",
    "mass_unit = ds_combined[species].attrs['units'].split()[0] #this will either be metric_Ton or moles depending on the species chosen\n",
    "ds = ds_combined.sum(dim=['utc_hour','sector'])[species].assign_attrs({'units':f'{mass_unit} day^-1 meters^-2'})\n",
    "month_sums = [] \n",
    "for yr_mo in ds.yr_mo.values:\n",
    "    yr = int(yr_mo.split('-')[0])\n",
    "    mo = int(yr_mo.split('-')[1])\n",
    "    sat,sun,wkdy = get_satsunwkd(yr,mo)\n",
    "    sat_sum = (ds.sel(yr_mo=yr_mo,day_type='satdy')*sat).assign_attrs({'units':f'{mass_unit} month^-1 meters^-2'})\n",
    "    sun_sum = (ds.sel(yr_mo=yr_mo,day_type='sundy')*sun).assign_attrs({'units':f'{mass_unit} month^-1 meters^-2'})\n",
    "    wkdy_sum = (ds.sel(yr_mo=yr_mo,day_type='weekdy')*wkdy).assign_attrs({'units':f'{mass_unit} month^-1 meters^-2'})\n",
    "    month_sum = xr.combine_by_coords([sat_sum.to_dataset(name='sat'),\n",
    "                                    sun_sum.to_dataset(name='sun'),\n",
    "                                    wkdy_sum.to_dataset(name='wkdy')\n",
    "                                    ],compat='override').to_array().sum(\"variable\").drop_vars('day_type').assign_attrs({'units':f'{mass_unit} month^-1 meters^-2'})\n",
    "    month_sums.append(month_sum.to_dataset(name=yr_mo))\n",
    "yr_sum = xr.combine_by_coords(month_sums,compat='override').to_array().sum(\"variable\").drop_vars('yr_mo').assign_attrs({'units':f'{mass_unit} meters^-2'})\n",
    "grid_area = xr.open_dataset('../regridding/grid_area/grid_out_area.nc')\n",
    "grid_area = slice_extent(grid_area,dataset_extent)\n",
    "absolute_emissions = (yr_sum * grid_area['cell_area']).assign_attrs({'units':mass_unit})\n",
    "area_sum = absolute_emissions.sum().values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get point sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors = 'point'\n",
    "\n",
    "#Get the paths to the files that match the criteria\n",
    "days_paths = RCH.get_days_in_range(dt1,dt2,day_types,sectors) \n",
    "files = RCH.get_files_in_days(days_paths)\n",
    "\n",
    "#Load the files with xarray, preprocessing them so they can be combined by coordinates\n",
    "ds_list = [] #initialize the list of datasets\n",
    "for file in files:\n",
    "    ds = preprocess_regridded(xr.open_dataset(file,chunks = {'utc_hour':1}),dataset_extent,sectors)[species] #prepreprocess the file, open with dask chunking, and only keep the species of interest\n",
    "    ds_list.append(ds)  \n",
    "ds_combined = xr.combine_by_coords(ds_list,combine_attrs='drop_conflicts') #this is the combined dataset!\n",
    "mass_unit = ds_combined[species].attrs['units'].split()[0] #this will either be metric_Ton or moles depending on the species chosen\n",
    "ds = ds_combined.sum(dim=['utc_hour','sector'])[species].assign_attrs({'units':f'{mass_unit} day^-1 meters^-2'})\n",
    "month_sums = [] \n",
    "for yr_mo in ds.yr_mo.values:\n",
    "    yr = int(yr_mo.split('-')[0])\n",
    "    mo = int(yr_mo.split('-')[1])\n",
    "    sat,sun,wkdy = get_satsunwkd(yr,mo)\n",
    "    sat_sum = (ds.sel(yr_mo=yr_mo,day_type='satdy')*sat).assign_attrs({'units':f'{mass_unit} month^-1 meters^-2'})\n",
    "    sun_sum = (ds.sel(yr_mo=yr_mo,day_type='sundy')*sun).assign_attrs({'units':f'{mass_unit} month^-1 meters^-2'})\n",
    "    wkdy_sum = (ds.sel(yr_mo=yr_mo,day_type='weekdy')*wkdy).assign_attrs({'units':f'{mass_unit} month^-1 meters^-2'})\n",
    "    month_sum = xr.combine_by_coords([sat_sum.to_dataset(name='sat'),\n",
    "                                    sun_sum.to_dataset(name='sun'),\n",
    "                                    wkdy_sum.to_dataset(name='wkdy')\n",
    "                                    ],compat='override').to_array().sum(\"variable\").drop_vars('day_type').assign_attrs({'units':f'{mass_unit} month^-1 meters^-2'})\n",
    "    month_sums.append(month_sum.to_dataset(name=yr_mo))\n",
    "yr_sum = xr.combine_by_coords(month_sums,compat='override').to_array().sum(\"variable\").drop_vars('yr_mo').assign_attrs({'units':f'{mass_unit} meters^-2'})\n",
    "point_sum = yr_sum.sum().values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48787.23965782996 metric_Ton CO\n"
     ]
    }
   ],
   "source": [
    "total_sum = area_sum + point_sum\n",
    "print(total_sum,mass_unit,species)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "noaa_csl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
